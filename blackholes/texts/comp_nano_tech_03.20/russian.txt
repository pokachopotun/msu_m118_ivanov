Поиск паттерна "Черная дыра" в направленном графе при помощи топологии.

Аннотация.
В данной статье мы рассматриваем задачу поиска паттерна "черная дыра" в направленных невзвешенных графах. Мы анализируем уже существующие алгоритмы и подходы. Затем, описываем как структура графа сказывается на эффективности алгоритма. В попытке разрешить обозначенные сложности, мы предлагаем свой алгоритм решения предложенной задачи. Он состоит из двух частей: алгоритм предобработки графа и эвристика для сокращения последующего перебора черных дыр. Наконец, мы приводим результаты экспериментального сравнения нашего подхода с ранее опубликованными.

Ключевые слова: направленные графы, поиска паттернов в графе, паттерн "черная дыра".

Введение.
Интересным свойством графов, которые описывают реальные системы, является образование там кластеров или сообществ. Определение сообществ имеет важное значение в социологии , биологии и компьютерных науках, поскольку системы, изучаемые в данных джисциплинах часто представимы графами[4].
    В 2010 Li et al. [8] впервые сформулировал задачу поиска паттернов "черная дыра" и "вулкан" в больших направленных графах. Черная дыра представляет собой множество вершин графа без исходящих ребер. Вулкан же является полной противополоожностью, и может иметь только исходящие ребра.
    Оба паттерна можно обнаружить в реальном мире. Например, в торговой сети, паттерн черная дыра может представлять собой группу торговцев, которые манипулируют рынком. Также, черная дыра и вулкан могут описывать собой схемы отмывания денег [9]. Поиск черных дыр и вулканов в реальном времени может своевременно обнаружить пагубные явления, такие как природные катаклизмы, катастрофы, неприятные случайности. Реализация таких алгоритмов позволила бы сохранять общественную безопасность. [5]
    Основной вклад в исследование поиска паттерная черная дыра внесли группа автором из университета Нью-Джерси. Они сформулировали задачу и предложили алгоритм поиска черных дыр в случае невзвешенного направленного графа [8]. Два года спустя, они опубликовали алгоритм для приближенного поиска черных дыр в случае взвешенного графа [6,7]. Hong et al. [5] рассматривает использование поиска черных дыр в городском окружении. Он вводит оригинальный алгоритм приближенно решающий задачу для динамических графов.
    В данной статье мы рассматриваем упрощенную постановку задачи для случая напрвленноого, невзвешенного графа.

2 (ЗАГОЛОВОК)

В этом разделе мы приводим основные обозначения и определения, которые будут использованы далее в тексте.

2.1. Постановка задачи

Рассмтрим граф G(v,e), где v множество вершин, а Е - множество ребер.

Определение 1. TODO

Целью ставим определить как можно больше черных дыр в напрвленном невзвешенном графе за ограниченное время.

2.2. Определения

Введем несколько дополнительных определений

Определение 2. TODO
Определение 3. TODO
Определение 4. TODO
Определение 5. TODO
Определение 6. TODO

Следующие утверждения доказываются в статье [8].

Лемма 1.
Лемма 2.
Лемма 3.

2.3 Известные проблемы

В данном разделе мы обсуждаем применимость алгоритма iBlackhole, предложенного в статье [8]. Этот алгоритм (см. Алгоритм 1.) создан для поиска черных дыр фиксированного размера. Он имеет значительный ресурс параллелизма, однако в работе [8] не рассматривается случай больших графов. Испытания проводятся на сетях до 1500 узлов, что относительно мало.
    Нам потребуются дополнительные утверждения, чтобы описать проблемы существующего подхода.
    
Лемма 4.

Доказательноство.
    В SCC любая вершина доступна из любой друго вершины. Это значит, что замыкание любой вершины в SCC содержит всю SCC как подмножество. Опираясь на Лемму 3, получаем, что SCC принадлежит той же черной дыре, что и вершина v.

    Также существуют графы, которые имеют сравнительно небольшое количество черных дыр, относительно количества вершин. Они состоят из нескольких больших КСС и относительно малого числа независимых листьев или корней. В связи с этим, возникает два вопроса по поводу применимости алгоритма iBlackhole:
    - Можно ли быть уверенными, что в графе содержатся черные дыры заданного размера? В общем случае, необходимо проверить все возможные размеры, что займет много времени даже в параллельном режиме.
    - Как можно сократить область поиска на стадии полного перебора и избежать повторных проверок уже увиденных комбинаций вершин?

    Давайте рассмотрим следующий пример. Граф состоит из 10е6 вершин, которые образуют единую КСС. Это значит, что в данном графе существует только одна черная дыра - это весь граф. Пока мы не знаем ничего о структуре графа и не обладаем достаточно большими вычислительными ресурсами, шанс угадать нужный размер составляет один к миллиону, что непозволительно мало. В худшем случае нам придется последовательно перебрать все возможные размеры графа.
    
Другой пример - это графы малого мира [11]. Большая часть вершин такого графа содержится в единственной большой КСС. Также имеется парочка вершин и корней. Мы утверждаем, что при просмотре от меньших размеров черной дыры к большим, алгоритм iBlackhole быстро обнаружит все небольшие черные дыры. Далее он будет очень долго пытаться найти черные дыры внутри КСС, где их попросту нет, пока не доберется до размеров больше размера КСС.

3 Разработка топологического алгоритм

Мы предлагаем рассмотреть задачу поиска черных дыр как комбинацию двух задач. Первая состоит в предобработке графа. На данном этапе мы стремимся упростить структуру графа настолько, насколько это возможно в ограниченный промежуток времени. Уменьшение масштаба графа (а значит, и размерности задачи) значительно упрощает вычисления, которые в худшем случае являют собой полный перебор вариантов. Второй этап - это непосредственно поиск черных дыр. Целью данного этапа стоит обнаружение как можно большего числа черных дыр при заданном ограничении по времени.

3.1 Обработка графа.
Как было сказано выше, большие КСС требуют значительных вычислительных ресурсов для обработки и при этом не образуют дополнительных черных дыр. Это может быть критично при обработке графов малого мира, потому что одна КСС может включать до 100% вершин заданного графа. В таком случае будет удобно рассмотреть КСС как единую вершину, которая объединяет в себе все входящие и исходящие связи периферических вершин КСС. На стадии предобратки мы сжимаем каждую КСС в единственную вершину. Процесс известен как конденсация графа.

Определение 7.

В данной работе мы используем алгоритм Шарира для поиска конденсации графа. [10]

3.2 Поиск черных дыр.

Когда граф подготовлен, мы можем переходить к поиску черных дыр. Задача имеет комбинаторную природу, поэтому мы стремимся уменьшить число потенциальных кандидатов. Для лучшего понимания, опишем сначала подход основанный на полном переборе вершин.

Определение 8.
Определение 9.

    Заметим, что базис черной дыры может состоять из произвольного числа вершин отличного от нуля.
    Во время полного перебора мы просматриваем все возможные неупорядоченные подмножества вершин графа. Далее для каждой вершины мы получаем ее замыкание. Объединение всех таких замыканий является потенциальной черной дырой. Если кандидат является слабо связным подграфом, тогда это черная дыра.
    Такой подход не застрахован от повторного обнаружения уже известной черной дыры. Мы задаемся целью уменьшить количество таких ситуаций и вводим эвристику.
    Согласно определениям данным выше, если какая-то вершина не является корнем черной дыры, то она может быть опущена, т.к. набор корней описывает черную дыру единственным образом. Каждая не корневая вершина в черной дыре достижима из какого-то корня этой дыры. Значит, если мы располагаем матрицей достижимости для данного графа, то мы можем эффективно определять лишние, не являющиеся базисами, комбинации вершин. Конечно же, мы могли бы прямо вычислить такую матрицу достижимости, но это вычислительно сложная задача O(v^3), что не позволяет применить такое правило для особенно больших графов. Мы можем столкнуться с нехваткой как памяти, так и времени  на предобработку. Надо отметить, что неплохо бы получить первые черные дыры как можно скорее после старта, что ограничивает нас в использовании особенно дорогих вычислений. Поэтому, мы воспользуемся эвристикой, которая является частным случаем описанного правила, чтобы частично сократить поле перебора, не жертвуя временем первого ответа. Те дубликаты, которые не могут быть отфильтрованы эвристикой, будут проверены "в лоб".
    Далее мы используем идею топологчиеской сортировки графа.

Определение 10.
Определение 11.

Замечание 1. Решение о том, является ли вершина особой принимается независимо в поддереве каждого корня. Одна и та же вершина может быть особой в поддереве одного корня и не являться таковой в поддерве другого корня. Пример такой ситуации отображен на Рис 1.

Опредление 12.

Замечание 2.
    Если дано две особых вершины под одним корнем, то одна из них всегда будет доминировать над другой.

Теорема 1.
Теорема 2.

Определение 13. Те вершины графа G(v,e), которые не имеют входящих ребер, называются глобальными корнями.

    Рассмотрим две вершины в замыкании глобального корня. Одна из них особая, а другая обычная. Чтобы эти две вершины образовали базис, особая вершина не должна доминировать над обычной. В противном случае обычная вершина могла бы быть опущена как не значимая. В общем случае, если дан набор вершин, мы можем опустить все доминируемые вершины и получить корректный базис.

    Алгоритм 2. IsBasis проверяет является ли набор вершин базисом. Этот алгоритм принимает набор вершин и возвращает True, если данный набор образует базис и False в противном случае. Этот алгоритм используется как составная часть алгоритма TopSort (Алгоритм 3), который перебирает наборы-кандидаты и отфильтровывает некорректные наборы. Если IsBasis возвращает False для кандидата, то этот набор может быть пропущен.
    IsBasis действует следующим образом.
    В первую очередь нам нужно знать, какие вершины являются особыми. Этот шаг может быть предпосчитан. Чтобы определить особые вершины, мы строим топологическую сортировку замыкания для каждого глоабльного корня. Далее по определению отмечаем особые вершины.
    Вторым шагом, если мы находим, что какие-то вершины доминируемы, то мы опускаем данный набор вершин.
    Шаг третий. У нас закончились дешевые методы принятия решения. Проверяем попарную достижимость вершин в наборе. Если найдется хоть одна такая пара, опускаем данный набор вершин.
    Если ни одна из предыдущих проверок на ответила False(опустить), то IsBasis возвращет True. Это значение возращается в алгоритм TopSort и означает, что мы имеем дело с корректным базисом черной дыры. Для получения черной дыры мы должны, согласно определению, объединить все замыкания базисных вершин. Последним шагом убедимся, что полученное множество является слабо связным, это будет означать, что мы получили черную дыру.
    Очевидно, что процесс не оптимален, но испытания демонстрируют его эффективность. Мы успешно избегаем дорогой проверки на слабую связность в большом числе случаев.
    
4 Результаты эксперимента

Чтобы показать эффективность нашего подхода, мы провели серию экспериментов. Сравнивали iBlackhole и TopSort алгоритмы. Для данных экспериментов мы выбрали равномерно случайные (UR)[3], RMAT [2] SSCA2 [1] типы графов. Они были сгенерированы для масштабов от 4 до 22 с шагом 2. Масштаб i означает, что граф имеет 2^i вершин и приблизительно 32 * V ребер.
    Эксперименты были проведены на ноутбуке под управлением Linux со следующими характеристиками:
    – CPU: Intel Core i7-8550U CPU @ 4GHz
– RAM: 15802 MiB
– OS: Ubuntu 16.04 xenial
– Kernel: x86 64 Linux 4.15.0-46-generic
– Shell: bash 4.3.48


    Все запуски были выполнены в однопоточном режиме. Мы установили ограничение на один запуск в 20 минут. Это время включает в себя препроцессинг и отбор черных дыр.
    На рисунках 2, 3 и 4 видно, что наш алгоритм TopSort уверенно лидирует на небольших RMAT графах и сохраняет преимущество вплоть до RMAT-22. Как видно, предобработка с конденсацией графа занимает больше времени на больших графах, что увеличивает время работы до первой найденной черной дыры. Тем не менее, наш алгоритм показывает значительно лучшую производительность в тех случаях, когда предобработка позволяет сэкономить больше времени. Также, мы полагаем, что общее время работы на больших графах для нашего алгоритма будет меньше, чем у конкурентов, что будет исследовано нами в будущем.

    SSCA2 графы в нашем эксперименте оказались абсолютно лишены КСС состоящих из более чем одной вершины. Здесь предобработка не дает ускорения, а только лишь тратит время. На небольших графах наш алгоритм выигрывает у iBlackhole, но сдае позиции при обработке больших размеров. Мы предполагаем, что причиной может служить  менее эффективный порядок перебора в нашем алгоритме. iBlackhole перебирает размеры последовательно, в то время как наш алгоритм рассматривает дыры по возрастанию размера базис-кандидата, что совершенно не означает увеличения размера черной дыры.
    Наконец, надо отметить, наша предобработка имеет огромное значение на графах, где черные дыры отсутствуют вовсе (или весь граф является черной дырой). В данном случае стадия перебора вырождается до единственного случая с одной конденсированной вершиной, делая время обработки впечатляюще малым по сравнению с алгоритмом iBlackhole.

5 Заключение.

В данной статье мы рассмотрели проблемы связанные с использованием уже известного iBlackhole алгоритма. Мы предложили и протестировали две идеи для оптимизации, которые вместе назвали алгоритм TopSort. Это предобработка-конденсация и далее эвристика для сокращения перебора. Мы проверили наш подход на трех различных видах графов в различных масштабах. Мы впервые описываем поиск черных дыр для графов состоящих из более миллиона вершин. 
    Для графов содержащих большие компоненты сильной связности, мы демонстрируем уверенное преимущество в скорости работы перед алгоритмом iBlackhole. Кроме того, мы умеем относительно быстро определять ситуацию полного отсутствия черных дыр. Однако в ряде случаев, довольно дорогая предобработка нивелирует выигрыш по времени поиска, ухудшая производительность нашего алгоритма.












